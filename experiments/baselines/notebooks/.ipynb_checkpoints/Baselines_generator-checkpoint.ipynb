{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/svr.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/svr.py\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "C = (1, 5, 10, 20, 50)\n",
    "kernel = ('linear', 'rbf', 'sigmoid')\n",
    "param_grid = {'C':C, 'kernel':kernel}\n",
    "svr = SVR()\n",
    "cvmodel = GridSearchCV(svr, param_grid, refit=True, cv=5)\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "cvmodel.fit(trn_X, trn_y.ravel())\n",
    "pred_y = scaler.inverse_transform(cvmodel.predict(tst_X))\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "pd.to_pickle(cvmodel, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../scripts/rf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/rf.py\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "param_grid = {'n_estimators':[50,100,150,200], \n",
    "              'max_depth':[1,2,3,4,5,20],\n",
    "              'max_features':[1,2,3,4,5,6]}\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "cvmodel = GridSearchCV(rf, param_grid, refit=True, cv=5)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "cvmodel.fit(trn_X, trn_y.ravel())\n",
    "\n",
    "pred_y = scaler.inverse_transform(cvmodel.predict(tst_X))\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "pd.to_pickle(cvmodel, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../scripts/dt.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/dt.py\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "param_grid = {'max_depth':[1,2,3,4,5,20],\n",
    "              'max_features':[1,2,3,4,5,6]}\n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "cvmodel = GridSearchCV(dt, param_grid, refit=True, cv=5)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "cvmodel.fit(trn_X, trn_y.ravel())\n",
    "\n",
    "pred_y = scaler.inverse_transform(cvmodel.predict(tst_X))\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "pd.to_pickle(cvmodel, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../scripts/elst.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/elst.py\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "param_grid = {'alpha':[0.1,0.5,1,5,10], \n",
    "              'l1_ratio':[0.1,0.3,0.5,0.7,0.9]}\n",
    "elst = ElasticNet(random_state=0)\n",
    "\n",
    "cvmodel = GridSearchCV(elst, param_grid, refit=True, cv=5)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "cvmodel.fit(trn_X, trn_y.ravel())\n",
    "\n",
    "pred_y = scaler.inverse_transform(cvmodel.predict(tst_X))\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "pd.to_pickle(cvmodel, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/gp_linear.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/gp_linear.py\n",
    "from stheno import Measure, GP, Linear, Delta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "prior = Measure()                  # Construct a prior.\n",
    "f1 = GP(Linear(), measure=prior)        # Define our probabilistic model.\n",
    "f2 = GP(Delta(), measure=prior)\n",
    "f = f1+f2\n",
    "post = prior | (f(trn_X), trn_y)           # Compute the posterior distribution.\n",
    "pred = post(f).mean(tst_X).mat\n",
    "\n",
    "pred_y = scaler.inverse_transform(pred)\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "# pd.to_pickle(model.param_array, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/gp_rbf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/gp_rbf.py\n",
    "from stheno import Measure, GP, EQ, Delta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "np.random.seed(0)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "prior = Measure()                  # Construct a prior.\n",
    "f1 = GP(EQ(), measure=prior)        # Define our probabilistic model.\n",
    "f2 = GP(Delta(), measure=prior)\n",
    "f = f1+f2\n",
    "post = prior | (f(trn_X), trn_y)           # Compute the posterior distribution.\n",
    "pred = post(f).mean(tst_X).mat\n",
    "\n",
    "pred_y = scaler.inverse_transform(pred)\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "# pd.to_pickle(model.param_array, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - Matern12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/gp_m12.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/gp_m12.py\n",
    "from stheno import Measure, GP, Matern12, Delta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "np.random.seed(0)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "prior = Measure()                  # Construct a prior.\n",
    "f1 = GP(Matern12(), measure=prior)        # Define our probabilistic model.\n",
    "f2 = GP(Delta(), measure=prior)\n",
    "f = f1+f2\n",
    "post = prior | (f(trn_X), trn_y)           # Compute the posterior distribution.\n",
    "pred = post(f).mean(tst_X).mat\n",
    "\n",
    "pred_y = scaler.inverse_transform(pred)\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "# pd.to_pickle(model.param_array, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - Matern32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/gp_m32.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/gp_m32.py\n",
    "from stheno import Measure, GP, Matern32, Delta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "np.random.seed(0)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    "\n",
    "prior = Measure()                  # Construct a prior.\n",
    "f1 = GP(Matern32(), measure=prior)        # Define our probabilistic model.\n",
    "f2 = GP(Delta(), measure=prior)\n",
    "f = f1+f2\n",
    "post = prior | (f(trn_X), trn_y)           # Compute the posterior distribution.\n",
    "pred = post(f).mean(tst_X).mat\n",
    "\n",
    "pred_y = scaler.inverse_transform(pred)\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)\n",
    "# pd.to_pickle(model.param_array, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/nsgp_rbf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/nsgp_rbf.py\n",
    "# from stheno import Measure, GP, EQ, Delta\n",
    "import GPy\n",
    "from polire.placement.base import Base\n",
    "from NSGPy.NumPy import LLS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "np.random.seed(0)\n",
    "\n",
    "model_name = sys.argv[0].split('/')[-1].replace('.py','')\n",
    "path = sys.argv[1]\n",
    "fold = sys.argv[2]\n",
    "f_id = sys.argv[3]\n",
    "N_l_bar_max = 8\n",
    "\n",
    "trn_X = np.load(path+'data/fold_'+fold+'/train/X/'+f_id+'.npy')\n",
    "trn_y = np.load(path+'data/fold_'+fold+'/train/y/'+f_id+'.npy')\n",
    "tst_X = np.load(path+'data/fold_'+fold+'/test/X/'+f_id+'.npy')\n",
    "\n",
    "scaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/'+f_id+'.pickle')\n",
    " \n",
    "m = GPy.models.GPRegression(trn_X, trn_y, GPy.kern.RBF(trn_X.shape[1], ARD=True))\n",
    "m.optimize()\n",
    "K = m.kern.K(trn_X)\n",
    "\n",
    "greedy = Base(verbose=False)\n",
    "greedy.cov_np = K\n",
    "inds, _ = greedy.place(trn_X, N=20)\n",
    "\n",
    "best_nlml = np.inf\n",
    "best_model = None\n",
    "for n in range(2,21):\n",
    "    model = LLS(trn_X.shape[1], N_l_bar=n, N_l_bar_method='greedy')\n",
    "    try:\n",
    "        model.fit(trn_X, trn_y, n_restarts=2, near_opt_inds=inds[:n])\n",
    "    except:\n",
    "        continue\n",
    "    nlml = model.params['likelihood (mll)']\n",
    "    print(nlml)\n",
    "    if nlml< best_nlml:\n",
    "        best_nlml = nlml\n",
    "        best_model = model\n",
    "        if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "            os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "#         pd.to_pickle(model.params, path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.model')\n",
    "\n",
    "pred_y = scaler.inverse_transform(best_model.predict(tst_X)[0])\n",
    "\n",
    "if not os.path.exists(path+'results/'+model_name+'/fold_'+fold+'/'):\n",
    "    os.makedirs(path+'results/'+model_name+'/fold_'+fold+'/')\n",
    "\n",
    "# np.save(path+'results/'+model_name+'/fold_'+fold+'/'+f_id+'.npy', pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
