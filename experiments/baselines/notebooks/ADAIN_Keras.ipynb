{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/patel-zeel/Adhoc/master/ADAIN.PNG\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -qq numpy==1.19.2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Lambda, Multiply, Reshape, Input, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('font', size=16)\n",
    "# import logging\n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADAIN(time_window, met_dim):\n",
    "    \"\"\"\n",
    "    # Vocab\n",
    "    met         - meteorology\n",
    "    dis         - distance\n",
    "    aq          - air quality\n",
    "    n_stn       - n_stations\n",
    "    dim         - dimension\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    do = 0.2 # Drop out\n",
    "    np.random.seed(0)\n",
    "    set_seed(0)\n",
    "    \n",
    "    # Defining inputs\n",
    "    train_dist = Input(shape=(2,None,))\n",
    "#     train_dist = Lambda(lambda x: K.permute_dimensions(x, (2,0,1)))(train_dist)\n",
    "    train_met_aq = Input(shape=(24,met_dim+1,None,)) # +1 for aq\n",
    "#     train_met_aq = Lambda(lambda x: K.permute_dimensions(x, (3,0,1,2)))(train_met_aq)\n",
    "    test_met = Input(shape=(24,met_dim,))\n",
    "    \n",
    "    n_stn = 29#2 if train_dist.shape[2] == None else train_dist.shape[2]\n",
    "    \n",
    "    # Local station                                                        ## Input                --- Output\n",
    "    lcl_lstm = LSTM(300, dropout=do)(test_met)                             # (-1,time_window,met)  --- (-1,300)\n",
    "    lcl_dns = Dense(200, activation='relu')(lcl_lstm)                      # (-1,300)              --- (-1,200) \n",
    "    lcl_dns = Dropout(do)(lcl_dns)\n",
    "    \n",
    "    # Defininig shared layers (shared among train stations)\n",
    "    s_dns1 = Dense(100, activation='relu')\n",
    "    s_lstm = LSTM(300, activation='relu', dropout=do)\n",
    "    s_dns2 = Dense(200, activation='relu')\n",
    "    \n",
    "    a_dns1 = Dense(200, activation='relu')\n",
    "    a_dns2 = Dense(200)\n",
    "    a_dns3 = Dense(1)\n",
    "    \n",
    "    # Training stations\n",
    "    att_list = [] # Saving station attention weights\n",
    "    stn_list = [] # Saving station features\n",
    "    \n",
    "    # Iterating over train stations using shared layers\n",
    "#     print(n_stn)\n",
    "#     def forward_once(d):                                            ## Input               --- Output\n",
    "    for s_i in range(n_stn):\n",
    "#         pd.to_pickle(s_i,str(s_i))\n",
    "        train_dist_slice = Lambda(lambda x:x[:,:,s_i])(train_dist)         # (-1,dis,n_stn)       --- (-1,dis)\n",
    "        stn_dns1 = s_dns1(train_dist_slice)                                # (-1,dis)             --- (-1,100)\n",
    "        stn_dns1 = Dropout(do)(stn_dns1)\n",
    "        train_met_aq_slice = Lambda(lambda x:x[:,:,:,s_i])(train_met_aq)\n",
    "        stn_lstm = s_lstm(train_met_aq_slice)                              # (-1,time_window,met) --- (-1,300)\n",
    "        stn_cat1 = Concatenate()([stn_dns1, stn_lstm])                     # (-1,100)+(-1,300)    --- (-1,400)\n",
    "        stn_dns2 = s_dns2(stn_cat1)                                        # (-1,400)             --- (-1,200)\n",
    "        stn_dns2 = Dropout(do)(stn_dns2)\n",
    "        stn_list.append(stn_dns2)\n",
    "        ### Attention Mechanism\n",
    "        att_cat = Concatenate()([stn_dns2, lcl_dns])                       # (-1,200)*2           --- (-1,400)\n",
    "        att_dns1 = a_dns1(att_cat)                                         # (-1,400)             --- (-1,200)\n",
    "        att_dns1 = Dropout(do)(att_dns1)\n",
    "        att_dns2 = a_dns2(att_dns1)                                        # (-1,200)             --- (-1,200)\n",
    "        att_dns3 = a_dns3(att_dns2)                                        # (-1,200)             --- (-1,1)\n",
    "        att_list.append(att_dns3)\n",
    "#         return stn_dns2, att_dns3\n",
    "\n",
    "#     stn_lst, att_lst = tf.map_fn(forward_once, [train_dist, train_met_aq])\n",
    "    ### Normalize Attention\n",
    "    att_cat1 = Concatenate()(att_list)                                     # (-1,1)*n_stn         --- (-1,n_stn)\n",
    "    att_cat2 = Lambda(lambda inp: inp/K.sum(inp, axis=0))(att_cat1)        # (-1,n_stn)           --- (-1,n_stn)\n",
    "    \n",
    "    ### Multiply Attention with station features\n",
    "    stn_cat2 = Concatenate()(stn_list)                                     # (-1,200)*n_station   --- (-1,200*n_stn) \n",
    "    stn_cat2 = Lambda(lambda x: K.reshape(x, (-1,200,n_stn)))(stn_cat2)    # (-1,200*n_stn)       --- (-1,200,n_stn)      \n",
    "    att_cat2 = Lambda(lambda x: K.reshape(x, (-1,1,n_stn)))(att_cat2)      # (-1,n_stn)           --- (-1,1,n_stn)\n",
    "#     print(stn_cat2)\n",
    "    stn_mul = Multiply()([stn_cat2, att_cat2])                             # (-1,200,n_stn)*(-1,1,n_stn)  --- (-1,200,n_stn)\n",
    "    stn_add = Lambda(lambda x: K.sum(x, axis=2))(stn_mul)                  # (-1,200,n_stn)       --- (-1,200)\n",
    "    \n",
    "    ### Concatenate local and station features\n",
    "    final_cat = Concatenate()([stn_add, lcl_dns])                          # (-1,200)*2           --- (-1,400)\n",
    "    final_dns1 = Dense(200, activation='relu')(final_cat)                  # (-1,400)             --- (-1,200)\n",
    "    final_dns1 = Dropout(do)(final_dns1)\n",
    "    final_dns2 = Dense(200)(final_dns1)\n",
    "    final_dns3 = Dense(1)(final_dns2)                                      # (-1,200)             --- (-1,1)\n",
    "    \n",
    "    model = Model(inputs=[train_dist, train_met_aq, test_met], outputs=final_dns3)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2\n",
      "weights loaded\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 45s 832ms/step - loss: 0.3658 - val_loss: 0.2138\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 46s 846ms/step - loss: 0.1920 - val_loss: 0.1406\n",
      "Epoch 3/10\n",
      "44/54 [=======================>......] - ETA: 8s - loss: 0.1479"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "set_seed(0)\n",
    "path = '../../../data_and_results/u-air/production/pm25_beijing_best36/quadratic/'\n",
    "n_folds = 6\n",
    "\n",
    "init = time()\n",
    "fold_history = []\n",
    "model = ADAIN(time_window=24, met_dim=4)\n",
    "model.save_weights('model.h5')\n",
    "for fold in [str(i) for i in range(n_folds)]:\n",
    "    clear_output(wait=True)\n",
    "    print('Training fold',fold)\n",
    "    \n",
    "    # Load initial weights\n",
    "    model.load_weights('model.h5')\n",
    "    print('weights loaded')\n",
    "    # Load data\n",
    "    train_dst = np.load(path+'data/fold_'+fold+'/train/adain/trn_dst.npy', allow_pickle=True).astype(np.float32)\n",
    "    train_met_aq = np.load(path+'data/fold_'+fold+'/train/adain/trn_metaq.npy').astype(np.float32)\n",
    "    test_met = np.load(path+'data/fold_'+fold+'/train/adain/tst_met.npy').astype(np.float32)\n",
    "    test_aq = np.load(path+'data/fold_'+fold+'/train/adain/tst_aqi.npy').astype(np.float32)\n",
    "    yscaler = pd.read_pickle(path+'data/fold_'+fold+'/scaler/adain/yscaler.pickle')\n",
    "#     print(train_dst.shape, train_met_aq.shape, test_met.shape)\n",
    "    # Define and train the model\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2, restore_best_weights=True)\n",
    "    history = model.fit(x=[train_dst, train_met_aq, test_met], y=test_aq, \n",
    "          batch_size=128, epochs=10, validation_split=0.1, verbose=1)#, callbacks=[es])\n",
    "    fold_history.append(history)\n",
    "    \n",
    "    # Test the model\n",
    "    train_dst = np.load(path+'data/fold_'+fold+'/test/adain/trn_dst.npy', allow_pickle=True).astype(np.float32)\n",
    "    train_met_aq = np.load(path+'data/fold_'+fold+'/test/adain/trn_metaq.npy').astype(np.float32)\n",
    "    test_met = np.load(path+'data/fold_'+fold+'/test/adain/tst_met.npy').astype(np.float32)\n",
    "    test_aq = np.load(path+'data/fold_'+fold+'/test/adain/tst_aqi.npy').astype(np.float32)\n",
    "    \n",
    "    pred_y = np.nan*np.zeros((train_dst.shape[0], train_dst.shape[-1]))\n",
    "    for test_id in range(train_dst.shape[-1]):\n",
    "        pred_yy = model.predict(x=[train_dst[:,:,:29,test_id], train_met_aq[:,:,:,:29], test_met[:,:,:,test_id]])\n",
    "        pred_y[:,test_id] = yscaler.inverse_transform(pred_yy).ravel()\n",
    "    \n",
    "    if not os.path.exists(path+'results/adain/fold_'+fold):\n",
    "        os.makedirs(path+'results/adain/fold_'+fold)\n",
    "    np.save(path+'results/adain/fold_'+fold+'/pred_y.npy', pred_y)\n",
    "    np.save(path+'results/adain/fold_'+fold+'/test_y.npy', test_aq)\n",
    "print('Finished in',round(time()-init)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data_and_results/u-air/production/pm25_beijing_best36/quadratic/'\n",
    "folds = [str(i) for i in range(6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, len(folds)//2, figsize=(15,6))\n",
    "ax = ax.ravel()\n",
    "for i in range(len(folds)):\n",
    "    ax[i].plot(fold_history[i].history['loss'], label='train loss')\n",
    "    ax[i].plot(fold_history[i].history['val_loss'], label='validation loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['svr', 'gp_rbf', 'gp_m32', 'gp_m12', 'gp_linear','nsgp_rbf','adain']\n",
    "res = pd.DataFrame(index=models, columns=['fold_'+str(i) for i in range(len(folds))]+['avg'])\n",
    "# for model in models[:-1]:\n",
    "#     pred_y, test_y = load_results(path, folds, f_ids, n_test, model)\n",
    "#     fold_rmse = fold_wise_rmse(pred_y, test_y, len(folds))\n",
    "#     fold_rmse.append(np.mean(fold_rmse))\n",
    "#     res.loc[model, :] = fold_rmse\n",
    "\n",
    "# ADAIN\n",
    "for fold in folds:\n",
    "    pred_y = np.load(path+'results/adain/fold_'+fold+'/pred_y.npy')\n",
    "    test_y = np.load(path+'results/adain/fold_'+fold+'/test_y.npy')\n",
    "    res.loc['adain', 'fold_'+fold] = mean_squared_error(test_y.ravel(), pred_y.ravel(), squared=False)\n",
    "res.loc['adain','avg'] = res.loc['adain'].mean()\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting predictions on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_aq.ravel(), test_aq.ravel())\n",
    "plt.scatter(test_aq.ravel(), pred_y.ravel());\n",
    "plt.xlabel('PM2.5 (Ground truth)');plt.ylabel('PM2.5 (Predictions)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(o_tests, o_tests)\n",
    "plt.plot(test_aq[:,0], label='ground truth');\n",
    "plt.plot(pred_y[:,0], label='predictions');\n",
    "plt.xlabel('Time-stamps'); plt.ylabel('PM2.5');\n",
    "plt.legend(bbox_to_anchor=(1.5,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.layers)\n",
    "# print(model.layers[10].get_config(), test_met.shape)\n",
    "get_layer_output = K.function(\n",
    "  [model.layers[0].input, model.layers[2].input, model.layers[91].input], \n",
    "  model.layers[-8].output)\n",
    "\n",
    "output = get_layer_output([train_dst[0:1,:,:29,0], train_met_aq[0:1,:,:], test_met[0:1,:,0]])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
