{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq boto3 botocore\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading data for August and Dec of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', config=botocore.config.Config(signature_version=botocore.UNSIGNED))\n",
    "bucket_name = 'openaq-fetches'\n",
    "prefix = 'realtime-gzipped/'\n",
    "\n",
    "path = '../raw_data/'\n",
    "\n",
    "start_date = '2019/12/01' # start date (inclusive)\n",
    "end_date = '2019/12/31' # end date (inclusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: 2019-12-31\n",
      "Finished Fetching. Downloading 4392 files\n",
      "Downloaded in 2.02 minutes\n"
     ]
    }
   ],
   "source": [
    "f_names = []\n",
    "for date in pd.date_range(start=start_date, end=end_date):\n",
    "    clear_output(wait=True)\n",
    "    date = str(date).split(' ')[0] # keeping just YYYY-MM-DD from YYYY-MM-DD HH:MM:SS\n",
    "    print('Fetching:', date)\n",
    "    data_dict = s3.list_objects(Bucket = bucket_name, Prefix = prefix+date)\n",
    "  \n",
    "    for file_obj in data_dict['Contents']:\n",
    "        f_name = file_obj['Key']\n",
    "        tmp_path = '/'.join((path+f_name).split('/')[:-1])\n",
    "    \n",
    "        if not os.path.exists(tmp_path):\n",
    "            os.makedirs(tmp_path)\n",
    "        \n",
    "        f_names.append(f_name)\n",
    "\n",
    "print('Finished Fetching. Downloading',len(f_names),'files')\n",
    "\n",
    "def download(f_name):\n",
    "    s3.download_file(bucket_name, f_name, path+f_name)\n",
    "\n",
    "workers = Pool()    \n",
    "\n",
    "init = time()\n",
    "workers.map(download, f_names)\n",
    "print('Downloaded in',round((time()-init)/60, 2),'minutes')\n",
    "workers.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated\n"
     ]
    }
   ],
   "source": [
    "for date in pd.date_range(start=start_date, end=end_date):\n",
    "    date = str(date).split(' ')[0] # keeping just YYYY-MM-DD from YYYY-MM-DD HH:MM:SS\n",
    "    data_dict = s3.list_objects(Bucket = bucket_name, Prefix = prefix+date)\n",
    "\n",
    "    for file_obj in data_dict['Contents']:\n",
    "        assert os.path.exists(path+file_obj['Key']), file_obj['Key']\n",
    "\n",
    "\n",
    "print('Validated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
