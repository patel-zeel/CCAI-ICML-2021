{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "802f07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from polire.placement.base import Base\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from time import time\n",
    "p = print\n",
    "\n",
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import rc\n",
    "\n",
    "from math import sqrt\n",
    "SPINE_COLOR = 'gray'\n",
    "p = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53bb549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latexify(fig_width=None, fig_height=None, columns=1):\n",
    "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n",
    "    Call this before plotting a figure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig_width : float, optional, inches\n",
    "    fig_height : float,  optional, inches\n",
    "    columns : {1, 2}\n",
    "    \"\"\"\n",
    "\n",
    "    # code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n",
    "\n",
    "    # Width and max height in inches for IEEE journals taken from\n",
    "    # computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf\n",
    "\n",
    "    assert(columns in [1,2])\n",
    "\n",
    "    if fig_width is None:\n",
    "        fig_width = 3.39 if columns==1 else 6.9 # width in inches\n",
    "\n",
    "    if fig_height is None:\n",
    "        golden_mean = (sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
    "        fig_height = fig_width*golden_mean # height in inches\n",
    "\n",
    "    MAX_HEIGHT_INCHES = 8.0\n",
    "    if fig_height > MAX_HEIGHT_INCHES:\n",
    "        print(\"WARNING: fig_height too large:\" + fig_height + \n",
    "              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n",
    "        fig_height = MAX_HEIGHT_INCHES\n",
    "\n",
    "    params = {'backend': 'ps',\n",
    "              'text.latex.preamble': [r'\\usepackage{gensymb}'],\n",
    "              'axes.labelsize': 10, # fontsize for x and y labels (was 10)\n",
    "              'axes.titlesize': 10,\n",
    "              'font.size': 10, # was 10\n",
    "              'legend.fontsize': 10, # was 10\n",
    "              'xtick.labelsize': 10,\n",
    "              'ytick.labelsize': 10,\n",
    "              'text.usetex': True,\n",
    "              'figure.figsize': [fig_width,fig_height],\n",
    "              'font.family': 'serif'\n",
    "    }\n",
    "\n",
    "    matplotlib.rcParams.update(params)\n",
    "\n",
    "def format_axes(ax):\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_color(SPINE_COLOR)\n",
    "        ax.spines[spine].set_linewidth(0.5)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b85eb4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7532745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>PM25_AQI_value</th>\n",
       "      <th>PM10_AQI_value</th>\n",
       "      <th>NO2_AQI_value</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>weather</th>\n",
       "      <th>station_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-08 14:26:00</th>\n",
       "      <td>1001</td>\n",
       "      <td>122.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>haidianbeibuxinqu</td>\n",
       "      <td>116.173553</td>\n",
       "      <td>40.09068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-08 14:26:00</th>\n",
       "      <td>1002</td>\n",
       "      <td>90.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>haidianbeijingzhiwuyuan</td>\n",
       "      <td>116.205311</td>\n",
       "      <td>40.00395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     station_id  PM25_AQI_value  PM10_AQI_value  \\\n",
       "time                                                              \n",
       "2013-11-08 14:26:00        1001           122.0            76.0   \n",
       "2013-11-08 14:26:00        1002            90.0            68.0   \n",
       "\n",
       "                     NO2_AQI_value  temperature  pressure  humidity  wind  \\\n",
       "time                                                                        \n",
       "2013-11-08 14:26:00           30.0         13.0    1020.0      33.0   2.0   \n",
       "2013-11-08 14:26:00           16.0          0.0    1021.0      75.0   2.0   \n",
       "\n",
       "                     weather             station_name   longitude  latitude  \n",
       "time                                                                         \n",
       "2013-11-08 14:26:00      3.0        haidianbeibuxinqu  116.173553  40.09068  \n",
       "2013-11-08 14:26:00      3.0  haidianbeijingzhiwuyuan  116.205311  40.00395  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('../data_and_results/u-air/production/pm25_beijing_best36/linear/linear_df.pickle')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b05d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014\n",
      " 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028\n",
      " 1029 1030 1031 1032 1033 1034 1035 1036]\n"
     ]
    }
   ],
   "source": [
    "global_all_stations = data.station_id.unique()\n",
    "p(global_all_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648013a",
   "metadata": {},
   "source": [
    "### Train, pool, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d30bdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import kmeans_plusplus\n",
    "all_locs = data[['longitude', 'latitude']].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb3518d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 6\n",
      "test 6\n",
      "pool 24\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "# global_test_stations = global_all_stations[kmeans_plusplus(all_locs, n_clusters=6, random_state=seed)[1]]\n",
    "global_test_stations = global_all_stations[np.random.choice(len(global_all_stations))]\n",
    "global_train_pool_stations = np.array(sorted(set(global_all_stations) - set(global_test_stations)))\n",
    "global_pool_stations, global_train_stations = train_test_split(global_train_pool_stations, test_size=6, random_state=seed)\n",
    "p('train', len(global_train_stations))\n",
    "p('test', len(global_test_stations))\n",
    "p('pool', len(global_pool_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bce3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(global_test_stations, 'global_test.station')\n",
    "pd.to_pickle(global_train_stations, 'global_train.station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ea2442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2) (6, 2) (24, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 239.04x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latexify(3.32, 2)\n",
    "trn_locs = data[data.station_id.isin(global_train_stations)][['longitude', 'latitude']].drop_duplicates().values\n",
    "tst_locs = data[data.station_id.isin(global_test_stations)][['longitude', 'latitude']].drop_duplicates().values\n",
    "pool_locs = data[data.station_id.isin(global_pool_stations)][['longitude', 'latitude']].drop_duplicates().values\n",
    "\n",
    "print(trn_locs.shape, tst_locs.shape, pool_locs.shape)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ss = 20\n",
    "ax.scatter(trn_locs[:,0], trn_locs[:,1], c='black', s=ss, marker='d', label='train')\n",
    "ax.scatter(pool_locs[:,0], pool_locs[:,1], c='tab:green', s=ss, marker='*', label='pool')\n",
    "ax.scatter(tst_locs[:,0], tst_locs[:,1], c='red', s=ss, label='test')\n",
    "ax.legend(bbox_to_anchor=(1,1));\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "fig.tight_layout()\n",
    "fig.savefig('imgs/tpt'+str(seed)+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812c9c6",
   "metadata": {},
   "source": [
    "### Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90f4114b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_id', 'PM25_AQI_value', 'PM10_AQI_value', 'NO2_AQI_value',\n",
       "       'temperature', 'pressure', 'humidity', 'wind', 'weather',\n",
       "       'station_name', 'longitude', 'latitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c12f2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 24\n",
    "all_time = data.index.unique()[:-1]\n",
    "data = data.loc[all_time]\n",
    "Xcols = ['longitude', 'latitude']#, 'temperature', 'pressure', 'humidity', 'wind']\n",
    "ycols = ['PM25_AQI_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cc5ed",
   "metadata": {},
   "source": [
    "### GP + MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4116b8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 2013-11-20 01:08:00 9\n",
      "1006\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "import GPy\n",
    "np.random.seed(0)\n",
    "\n",
    "train_stations = global_train_stations.copy().tolist()\n",
    "test_stations = global_test_stations.copy().tolist()\n",
    "pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "gpmi_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "gpmi_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "gpmi_deploys = []\n",
    "\n",
    "for t_i in range(0,data.index.unique().shape[0], window):\n",
    "#     print('train', len(train_stations))\n",
    "#     print('pool', len(pool_stations))\n",
    "    \n",
    "    tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "    train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "    test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "    pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "    xscaler = StandardScaler()\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler.fit(train_df[Xcols])\n",
    "    yscaler.fit(train_df[ycols])\n",
    "    \n",
    "    local_preds = []\n",
    "    local_tests = []\n",
    "    chosen_i_list = []\n",
    "    for local_t in tmp_df.index.unique():\n",
    "        clear_output(wait=True)\n",
    "        trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "        tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "        trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "        tst_y = test_df.loc[local_t][ycols]\n",
    "#         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "        \n",
    "#         kern_long = GPy.kern.Linear(1, ARD=True, active_dims=[0])\n",
    "#         kern_lat = GPy.kern.Matern32(1, ARD=True, active_dims=[1])\n",
    "#         kernel = kern_long + kern_lat\n",
    "        kernel = GPy.kern.Matern32(trn_X.shape[1], ARD=True)\n",
    "        model = GPy.models.GPRegression(trn_X, trn_y-trn_y.mean(), kernel, normalizer=False)\n",
    "        model.optimize_restarts(10, verbose=False, robust=True)\n",
    "        \n",
    "        gpmi_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)[0] + trn_y.mean()).ravel()\n",
    "        gpmi_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "    \n",
    "        pool_X = xscaler.transform(pool_df.loc[local_t][Xcols].values.reshape(-1, len(Xcols)))\n",
    "\n",
    "        K = model.kern.K(trn_X)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "        K_s = model.kern.K(pool_X, trn_X)\n",
    "        K_ss = model.kern.K(pool_X, pool_X)\n",
    "\n",
    "        ### Choosing next sensor\n",
    "        chosen_i = None\n",
    "        best_delta = -np.inf\n",
    "        numer = K_ss.diagonal() - (K_s@K_inv@K_s.T).diagonal()\n",
    "        for i in range(pool_X.shape[0]):\n",
    "            a_bar = sorted(set(range(pool_X.shape[0])) - set([i]))\n",
    "            second = K_ss[i, a_bar]\n",
    "            denom = K_ss[i,i] - second.reshape(1,-1)@np.linalg.pinv(K_ss[np.ix_(a_bar, a_bar)])@second.reshape(-1,1)\n",
    "\n",
    "            delta = numer[i]/denom\n",
    "            if delta>best_delta:\n",
    "                best_delta = delta\n",
    "                chosen_i = i\n",
    "        chosen_i_list.append(chosen_i)\n",
    "        p(t_i, local_t, chosen_i)\n",
    "    \n",
    "    # Choose mode of chosen values\n",
    "    chosen_i = stats.mode(chosen_i_list).mode[0]\n",
    "    print(pool_stations[chosen_i])\n",
    "    gpmi_deploys.append(pool_stations[chosen_i])\n",
    "    \n",
    "    # Updating pool and train\n",
    "    train_stations.append(pool_stations.pop(chosen_i))\n",
    "    train_stations = sorted(train_stations)\n",
    "gpmi_result_df_preds.to_pickle(\"gpmi\"+str(seed)+\".pred\")\n",
    "gpmi_result_df_tests.to_pickle('testdf'+str(seed)+'.pickle')\n",
    "pd.to_pickle(gpmi_deploys, 'gpmi'+str(seed)+'.dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1fcf2",
   "metadata": {},
   "source": [
    "### NSGP + MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdbec97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init = time()\n",
    "# from NSGPy.NumPy import LLS\n",
    "# np.random.seed(0)\n",
    "\n",
    "# train_stations = global_train_stations.copy().tolist()\n",
    "# test_stations = global_test_stations.copy().tolist()\n",
    "# pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "# nsgpmi_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "# nsgpmi_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "\n",
    "# for t_i in range(0,data.index.unique().shape[0], window):\n",
    "# #     print('train', len(train_stations))\n",
    "# #     print('pool', len(pool_stations))\n",
    "    \n",
    "#     tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "#     train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "#     test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "#     pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "#     xscaler = StandardScaler()\n",
    "#     yscaler = StandardScaler()\n",
    "#     xscaler.fit(train_df[Xcols])\n",
    "#     yscaler.fit(train_df[ycols])\n",
    "    \n",
    "#     local_preds = []\n",
    "#     local_tests = []\n",
    "#     chosen_i_list = []\n",
    "#     for local_t in tmp_df.index.unique():\n",
    "#         clear_output(wait=True)\n",
    "#         trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "#         tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "#         trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "#         tst_y = test_df.loc[local_t][ycols]\n",
    "# #         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "        \n",
    "# #         kern_long = GPy.kern.Linear(1, ARD=True, active_dims=[0])\n",
    "# #         kern_lat = GPy.kern.Matern32(1, ARD=True, active_dims=[1])\n",
    "# #         kernel = kern_long + kern_lat\n",
    "        \n",
    "#         model = LLS(trn_X.shape[1], N_l_bar=1, kernel='rbf')\n",
    "#         model.fit(trn_X, trn_y-trn_y.mean())\n",
    "        \n",
    "#         nsgpmi_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)[0] + trn_y.mean()).ravel()\n",
    "#         nsgpmi_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "    \n",
    "#         pool_X = xscaler.transform(pool_df.loc[local_t][Xcols].values.reshape(-1, len(Xcols)))\n",
    "        \n",
    "#         L = model.predict_lengthscales_(trn_X)\n",
    "#         K = model.K_(trn_X, L)\n",
    "#         K_inv = np.linalg.pinv(K)\n",
    "#         L_s = model.predict_lengthscales_(pool_X)\n",
    "#         K_s = model.K_(pool_X, L_s, trn_X, L)\n",
    "#         K_ss = model.K_(pool_X, L_s)\n",
    "\n",
    "#         ### Choosing next sensor\n",
    "#         chosen_i = None\n",
    "#         best_delta = -np.inf\n",
    "#         numer = K_ss.diagonal() - (K_s@K_inv@K_s.T).diagonal()\n",
    "#         for i in range(pool_X.shape[0]):\n",
    "#             a_bar = sorted(set(range(pool_X.shape[0])) - set([i]))\n",
    "#             second = K_ss[i, a_bar]\n",
    "#             denom = K_ss[i,i] - second.reshape(1,-1)@np.linalg.pinv(K_ss[np.ix_(a_bar, a_bar)])@second.reshape(-1,1)\n",
    "\n",
    "#             delta = numer[i]/denom\n",
    "#             if delta>best_delta:\n",
    "#                 best_delta = delta\n",
    "#                 chosen_i = i\n",
    "#         chosen_i_list.append(chosen_i)\n",
    "#         p(t_i, local_t, chosen_i)\n",
    "    \n",
    "#     # Choose mode of chosen values\n",
    "#     chosen_i = stats.mode(chosen_i_list).mode[0]\n",
    "#     print(pool_stations[chosen_i])\n",
    "    \n",
    "#     # Updating pool and train\n",
    "#     train_stations.append(pool_stations.pop(chosen_i))\n",
    "#     train_stations = sorted(train_stations)\n",
    "# nsgpmi_result_df_preds.to_pickle(\"nsgpmi\"+str(seed)+\".pred\")\n",
    "# p((time()-init)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5b468",
   "metadata": {},
   "source": [
    "### GP + Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f267216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017\n",
      "1027\n",
      "1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:243: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n",
      "1010\n",
      "1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009\n",
      "1016\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "np.random.seed(0)\n",
    "train_stations = global_train_stations.copy().tolist()\n",
    "test_stations = global_test_stations.copy().tolist()\n",
    "pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "gpvar_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "gpvar_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "gpvar_deploys = []\n",
    "\n",
    "for t_i in range(0, data.index.unique().shape[0], window):\n",
    "    tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "    train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "    test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "    pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "    xscaler = StandardScaler()\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler.fit(train_df[Xcols])\n",
    "    yscaler.fit(train_df[ycols])\n",
    "    \n",
    "    chosen_i_list = []\n",
    "    for local_t in tmp_df.index.unique():\n",
    "        trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "        tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "        trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "        tst_y = test_df.loc[local_t][ycols]\n",
    "#         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "\n",
    "#         kern_long = GPy.kern.Linear(1, ARD=True, active_dims=[0])\n",
    "#         kern_lat = GPy.kern.Matern32(1, ARD=True, active_dims=[1])\n",
    "#         kernel = kern_long + kern_lat\n",
    "        kernel = GPy.kern.Matern32(trn_X.shape[1], ARD=True)\n",
    "        model = GPy.models.GPRegression(trn_X, trn_y-trn_y.mean(), kernel, normalizer=False)\n",
    "        model.optimize_restarts(10, verbose=False, robust=True)\n",
    "        \n",
    "        gpvar_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)[0] + trn_y.mean()).ravel()\n",
    "        gpvar_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "    \n",
    "        pool_X = xscaler.transform(pool_df.loc[local_t][Xcols].values.reshape(-1, len(Xcols)))\n",
    "\n",
    "        K = model.kern.K(trn_X)\n",
    "        K_inv = np.linalg.pinv(K)\n",
    "        K_s = model.kern.K(pool_X, trn_X)\n",
    "        K_ss = model.kern.K(pool_X, pool_X)\n",
    "\n",
    "        ### Choosing next sensor\n",
    "        numer = K_ss.diagonal() - (K_s@K_inv@K_s.T).diagonal()\n",
    "        chosen_i = np.argmax(numer)\n",
    "        chosen_i_list.append(chosen_i)\n",
    "        \n",
    "    chosen_i = stats.mode(chosen_i_list).mode[0]\n",
    "    gpvar_deploys.append(pool_stations[chosen_i])\n",
    "    print(pool_stations[chosen_i])\n",
    "    # Updating pool and train\n",
    "    train_stations.append(pool_stations.pop(chosen_i))\n",
    "    train_stations = sorted(train_stations)\n",
    "gpvar_result_df_preds.to_pickle(\"gpvar\"+str(seed)+\".pred\")\n",
    "pd.to_pickle(gpvar_deploys, 'gpvar'+str(seed)+'.dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa2d8f",
   "metadata": {},
   "source": [
    "### GP + Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "079755a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "1021\n",
      "1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:243: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1002\n",
      "1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:243: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:137: RuntimeWarning:overflow encountered in square\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n",
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:484: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/GPy/kern/src/stationary.py:243: RuntimeWarning:invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "np.random.seed(0)\n",
    "\n",
    "train_stations = global_train_stations.copy().tolist()\n",
    "test_stations = global_test_stations.copy().tolist()\n",
    "pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "gprand_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "gprand_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "gprand_deploys = []\n",
    "\n",
    "for t_i in range(0,data.index.unique().shape[0], window):\n",
    "#     print('train', len(train_stations))\n",
    "#     print('pool', len(pool_stations))\n",
    "    \n",
    "    tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "    train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "    test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "    pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "    xscaler = StandardScaler()\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler.fit(train_df[Xcols])\n",
    "    yscaler.fit(train_df[ycols])\n",
    "    \n",
    "    for local_t in tmp_df.index.unique():\n",
    "        trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "        tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "        trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "        tst_y = test_df.loc[local_t][ycols]\n",
    "#         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "\n",
    "#         kern_long = GPy.kern.Linear(1, ARD=True, active_dims=[0])\n",
    "#         kern_lat = GPy.kern.Matern32(1, ARD=True, active_dims=[1])\n",
    "#         kernel = kern_long + kern_lat\n",
    "        kernel = GPy.kern.Matern32(trn_X.shape[1], ARD=True)\n",
    "        model = GPy.models.GPRegression(trn_X, trn_y-trn_y.mean(), kernel, normalizer=False)\n",
    "        model.optimize_restarts(10, verbose=False, robust=True)\n",
    "        \n",
    "        gprand_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)[0] + trn_y.mean()).ravel()\n",
    "        gprand_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "    \n",
    "    ### Choosing next sensor\n",
    "    np.random.seed(t_i)\n",
    "    chosen_i = np.random.choice(len(pool_stations))\n",
    "    gprand_deploys.append(pool_stations[chosen_i])\n",
    "    print(pool_stations[chosen_i])\n",
    "    \n",
    "    # Updating pool and train\n",
    "    train_stations.append(pool_stations.pop(chosen_i))\n",
    "    train_stations = sorted(train_stations)\n",
    "gprand_result_df_preds.to_pickle(\"gprand\"+str(seed)+\".pred\")\n",
    "pd.to_pickle(gprand_deploys, 'gprand'+str(seed)+'.dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b7b49",
   "metadata": {},
   "source": [
    "### GP+NoDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84c901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GPy\n",
    "# np.random.seed(0)\n",
    "# train_stations = global_train_stations.copy().tolist()\n",
    "# test_stations = global_test_stations.copy().tolist()\n",
    "# pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "# gpnod_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "# gpnod_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "\n",
    "# for t_i in range(0, data.index.unique().shape[0], window):\n",
    "#     tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "#     train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "#     test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "#     pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "#     xscaler = StandardScaler()\n",
    "#     yscaler = StandardScaler()\n",
    "#     xscaler.fit(train_df[Xcols])\n",
    "#     yscaler.fit(train_df[ycols])\n",
    "    \n",
    "#     chosen_i_list = []\n",
    "#     for local_t in tmp_df.index.unique():\n",
    "#         trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "#         tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "#         trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "#         tst_y = test_df.loc[local_t][ycols]\n",
    "# #         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "\n",
    "#         kern_long = GPy.kern.Matern32(1, ARD=True, active_dims=[0])\n",
    "#         kern_lat = GPy.kern.Matern32(1, ARD=True, active_dims=[1])\n",
    "#         kernel = kern_long * kern_lat\n",
    "#         model = GPy.models.GPRegression(trn_X, trn_y-trn_y.mean(), kernel, normalizer=False)\n",
    "#         model.optimize_restarts(10, verbose=False, robust=True)\n",
    "        \n",
    "#         gpnod_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)[0] + trn_y.mean()).ravel()\n",
    "#         gpnod_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "        \n",
    "# gpnod_result_df_preds.to_pickle(\"gpnod\"+str(seed)+\".pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5144bc8",
   "metadata": {},
   "source": [
    "### RF + Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e8a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 1008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(0)\n",
    "\n",
    "train_stations = global_train_stations.copy().tolist()\n",
    "test_stations = global_test_stations.copy().tolist()\n",
    "pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "rfrand_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "rfrand_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "rfrand_deploys = []\n",
    "\n",
    "for t_i in range(0,data.index.unique().shape[0], window):\n",
    "#     print('train', len(train_stations))\n",
    "#     print('pool', len(pool_stations))\n",
    "    \n",
    "    tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "    train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "    test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "    pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "    xscaler = StandardScaler()\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler.fit(train_df[Xcols])\n",
    "    yscaler.fit(train_df[ycols])\n",
    "    \n",
    "    local_preds = []\n",
    "    local_tests = []\n",
    "    for local_t in tmp_df.index.unique():\n",
    "        trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "        tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "        trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "        tst_y = test_df.loc[local_t][ycols]\n",
    "#         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "\n",
    "        model = RandomForestRegressor(random_state=0)\n",
    "        model.fit(trn_X, trn_y)\n",
    "        \n",
    "        rfrand_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)).ravel()\n",
    "        rfrand_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "    \n",
    "    ### Choosing next sensor\n",
    "    np.random.seed(t_i)\n",
    "    chosen_i = np.random.choice(len(pool_stations))\n",
    "    clear_output(wait=True)\n",
    "    rfrand_deploys.append(pool_stations[chosen_i])\n",
    "    print(t_i, pool_stations[chosen_i])\n",
    "    \n",
    "    # Updating pool and train\n",
    "    train_stations.append(pool_stations.pop(chosen_i))\n",
    "    train_stations = sorted(train_stations)\n",
    "rfrand_result_df_preds.to_pickle(\"rfrand\"+str(seed)+\".pred\")\n",
    "pd.to_pickle(rfrand_deploys, 'rfrand'+str(seed)+'.dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fcacfb",
   "metadata": {},
   "source": [
    "### RF-NoDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a9cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# np.random.seed(0)\n",
    "\n",
    "# train_stations = global_train_stations.copy().tolist()\n",
    "# test_stations = global_test_stations.copy().tolist()\n",
    "# pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "# rfnod_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "# rfnod_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "\n",
    "# for t_i in range(0,data.index.unique().shape[0], window):\n",
    "    \n",
    "#     tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "#     train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "#     test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "#     pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "#     xscaler = StandardScaler()\n",
    "#     yscaler = StandardScaler()\n",
    "#     xscaler.fit(train_df[Xcols])\n",
    "#     yscaler.fit(train_df[ycols])\n",
    "    \n",
    "#     for local_t in tmp_df.index.unique():\n",
    "#         trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "#         tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "#         trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "#         tst_y = test_df.loc[local_t][ycols]\n",
    "# #         p(trn_X.shape, tst_X.shape, trn_y.shape, tst_y.shape)\n",
    "\n",
    "#         model = RandomForestRegressor(random_state=0)\n",
    "#         model.fit(trn_X, trn_y)\n",
    "        \n",
    "#         rfnod_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)).ravel()\n",
    "#         rfnod_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "\n",
    "# rfnod_result_df_preds.to_pickle(\"rfnod\"+str(seed)+\".pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c3d7f",
   "metadata": {},
   "source": [
    "### RF+SVR+KNN QBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f01baf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner, CommitteeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4da977db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/modAL/models/base.py:155: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 2013-11-20 01:08:00 12\n",
      "1031\n",
      "7.631847973664602 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/patel_zeel/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "train_stations = global_train_stations.copy().tolist()\n",
    "test_stations = global_test_stations.copy().tolist()\n",
    "pool_stations = global_pool_stations.copy().tolist()\n",
    "\n",
    "qbc_result_df_preds = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "qbc_result_df_tests = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
    "qbc_deploys = []\n",
    "\n",
    "for t_i in range(0,data.index.unique().shape[0], window):\n",
    "    tmp_df = data.loc[all_time[t_i:t_i+window]]\n",
    "    \n",
    "    train_df = tmp_df[tmp_df.station_id.isin(train_stations)]\n",
    "    test_df = tmp_df[tmp_df.station_id.isin(test_stations)]\n",
    "    pool_df = tmp_df[tmp_df.station_id.isin(pool_stations)]\n",
    "    \n",
    "    xscaler = StandardScaler()\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler.fit(train_df[Xcols])\n",
    "    yscaler.fit(train_df[ycols])\n",
    "    \n",
    "    local_preds = []\n",
    "    local_tests = []\n",
    "    chosen_i_list = []\n",
    "    for local_t in tmp_df.index.unique():\n",
    "        clear_output(wait=True)\n",
    "        trn_X = xscaler.transform(train_df.loc[local_t][Xcols])\n",
    "        tst_X = xscaler.transform(test_df.loc[local_t][Xcols])\n",
    "        trn_y = yscaler.transform(train_df.loc[local_t][ycols])\n",
    "        tst_y = test_df.loc[local_t][ycols]\n",
    "        \n",
    "        learners = [ActiveLearner(estimator=RandomForestRegressor(random_state=0), X_training=trn_X, y_training=trn_y),\n",
    "                    ActiveLearner(estimator=SVR(), X_training=trn_X, y_training=trn_y),\n",
    "                    ActiveLearner(estimator=KNeighborsRegressor(n_neighbors=3), X_training=trn_X, y_training=trn_y)]\n",
    "        \n",
    "        def ensemble_regression_std(regressor, X):\n",
    "            _, std = regressor.predict(X, return_std=True)\n",
    "            return np.argmax(std)\n",
    "        \n",
    "        model = CommitteeRegressor(learner_list=learners, query_strategy=ensemble_regression_std)\n",
    "        \n",
    "        qbc_result_df_preds.loc[local_t,:] = yscaler.inverse_transform(model.predict(tst_X)).ravel()\n",
    "        qbc_result_df_tests.loc[local_t,:] = tst_y.values.ravel()\n",
    "        \n",
    "        pool_X = xscaler.transform(pool_df.loc[local_t][Xcols].values.reshape(-1, len(Xcols)))\n",
    "        \n",
    "        chosen_i, _ = model.query(pool_X)\n",
    "        chosen_i_list.append(chosen_i)\n",
    "        p(t_i, local_t, chosen_i)\n",
    "    \n",
    "    # Choose mode of chosen values\n",
    "    chosen_i = stats.mode(chosen_i_list).mode[0]\n",
    "    qbc_deploys.append(pool_stations[chosen_i])\n",
    "    print(pool_stations[chosen_i])\n",
    "    \n",
    "    # Updating pool and train\n",
    "    train_stations.append(pool_stations.pop(chosen_i))\n",
    "    train_stations = sorted(train_stations)\n",
    "qbc_result_df_preds.to_pickle(\"qbc\"+str(seed)+\".pred\")\n",
    "pd.to_pickle(qbc_deploys, 'qbc'+str(seed)+'.dep')\n",
    "p((time()-init)/60, 'minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
